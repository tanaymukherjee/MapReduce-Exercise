Command: $ docker run -v $(pwd):/usr/local/hadoop/py -it sequenceiq/hadoop-docker:2.7.1 /usr/local/hadoop/py/py_runner.sh grep
/
Starting sshd:                                             [  OK  ]
20/04/05 22:20:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [08bd0388d684]
08bd0388d684: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-08bd0388d684.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-08bd0388d684.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-08bd0388d684.out
20/04/05 22:21:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-08bd0388d684.out
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-08bd0388d684.out
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

20/04/05 22:21:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Safe mode is OFF
20/04/05 22:21:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/04/05 22:21:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/04/05 22:21:31 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
20/04/05 22:21:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
packageJobJar: [/usr/local/hadoop/py/grep/mapper.py, /usr/local/hadoop/py/grep/reducer.py, /tmp/hadoop-unjar6732195149235743148/] [] /tmp/streamjob7965355849268990088.jar tmpDir=null
20/04/05 22:21:33 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/04/05 22:21:33 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
20/04/05 22:21:34 INFO mapred.FileInputFormat: Total input paths to process : 2
20/04/05 22:21:34 INFO mapreduce.JobSubmitter: number of splits:2
20/04/05 22:21:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1586139678337_0001
20/04/05 22:21:35 INFO impl.YarnClientImpl: Submitted application application_1586139678337_0001
20/04/05 22:21:35 INFO mapreduce.Job: The url to track the job: http://08bd0388d684:8088/proxy/application_1586139678337_0001/
20/04/05 22:21:35 INFO mapreduce.Job: Running job: job_1586139678337_0001
20/04/05 22:21:43 INFO mapreduce.Job: Job job_1586139678337_0001 running in uber mode : false
20/04/05 22:21:43 INFO mapreduce.Job:  map 0% reduce 0%
20/04/05 22:21:51 INFO mapreduce.Job:  map 100% reduce 0%
20/04/05 22:21:58 INFO mapreduce.Job:  map 100% reduce 100%
20/04/05 22:21:58 INFO mapreduce.Job: Job job_1586139678337_0001 completed successfully
20/04/05 22:21:59 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=124
                FILE: Number of bytes written=357616
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=276
                HDFS: Number of bytes written=13
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=11848
                Total time spent by all reduces in occupied slots (ms)=5383
                Total time spent by all map tasks (ms)=11848
                Total time spent by all reduce tasks (ms)=5383
                Total vcore-seconds taken by all map tasks=11848
                Total vcore-seconds taken by all reduce tasks=5383
                Total megabyte-seconds taken by all map tasks=12132352
                Total megabyte-seconds taken by all reduce tasks=5512192
        Map-Reduce Framework
                Map input records=2
                Map output records=14
                Map output bytes=90
                Map output materialized bytes=130
                Input split bytes=214
                Combine input records=0
                Combine output records=0
                Reduce input groups=4
                Reduce shuffle bytes=130
                Reduce input records=14
                Reduce output records=2
                Spilled Records=28
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=182
                CPU time spent (ms)=2330
                Physical memory (bytes) snapshot=620199936
                Virtual memory (bytes) snapshot=2180075520
                Total committed heap usage (bytes)=463470592
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=62
        File Output Format Counters
                Bytes Written=13
20/04/05 22:21:59 INFO streaming.StreamJob: Output directory: /usr/local/hadoop/py-output
20/04/05 22:22:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
foo     6
quux    4